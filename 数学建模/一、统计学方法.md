## 一、统计学方法

1. 多元回归
   * 方法概述：定量地描述**某一现象和某些因素之间**的函数关系，将各变量的已知值代入回归方程，可以求出**因变量的估计值**，从而可进行**预测**等相关研究。
   * 分类：**多元线性回归**；**非线性回归**——可通过一定的转换，**变为线性回归**。如 $y=ln x$ 可转化为$y = u,\quad u = lnx$ 来解决。
   * 注意事项：——好的检验结果可以体现出模型的优劣！
     1. **回归方程**的==显著性检验==——F检验
     2. **回归系数**的==显著性检验==——t检验
     3. **变量之间**存在**多重共线性问题**吗？
   
   > * F检验
   >   * F 检验的作用，就是做上面所说的显著性检验，简单来说。如果 A=B=C=0 时的模型 (weight=0)，是显著的，反过来就说明我们训练得到的 weight = A×age + B×height + C 是没有意义的。
   >   * 如果观测值定了，模型也估计出来了，那么就可以计算出 f 的取值，接着就可以从 F 分布表中查询到这个 f 取值出现的概率。**如果概率很小**，==说明这个 f 取值出现的**可能性很小**==，**也就是模型的参数全部为 0 的可能性很小**，**原模型明显是有意义的，是显著的**；如果这个概率比较大，比如超过 0.05,，我们所建的模型就不显著，
   > * t检验
   >   * 判断方式和 F 检验类似，也是用 t 统计量的取值去找对应的面积，进而找到这个 t 值出现的概率，最后根据这个概率值的大小来判定 t 值得合理性。
   
   * 使用步骤：
     1. 根据已知数据，预处理，得出**图形的大致趋势**或**数据之间的大致关系**
     2. **选取**适当的**回归方程**
     3. **拟合**回归参数
     4. **检验**：**回归方程**显著性检验及**回归系数**显著性检验
     5. 后续研究，如**预测**



2. ==单因素方差分析（待填坑）==

3. 主成分分析(PCA)

   * 方法概述：用少数变量来替代原先多个变量，将多个变量中有用的信息提取到少数几个变量中，即降维。——降维后（同时间接地去除**多重共线性**，剩下的变量都是显著能用的），后续可作**回归分析**。

   > * PCA 简而言之就是**根据输入数据的分布**，给**输入数据重新找到更能描述这组数据的正交的坐标轴**，比如下面一幅图，对于那个椭圆状的分布，最方便表示这个分布的坐标轴肯定是椭圆的长轴短轴而不是原来的 x ，y 轴。
   >
   > ![1567855181759](C:/Users/polic/AppData/Roaming/Typora/typora-user-images/1567855181759.png)
   >
   >  那么如何求出这个长轴和短轴呢？于是线性代数就来了：我们需要先求出这堆样本数据的**协方差矩阵**，然后再求出这个**协方差矩阵的特征值和特征向量**，对应最大特征值的那个特征向量的方向就是长轴 (也就是主元) 的方向，次大特征值的就是第二主元的方向，以此类推。
>
   > ![1567856188157](C:/Users/polic/AppData/Roaming/Typora/typora-user-images/1567856188157.png)
   >
   > 

   > * 数据压缩也不是随心所欲地压缩。我们的目标是：**让新数据的方差尽可能地大**。这样的标准能使得新数据尽可能地不丢失原有数据的信息，**因为方差越大，数据间的差异越大**。

*  PCA 的算法过程，用一句话来说，就是 “**将所有样本 X 减去样本均值 m，再乘以样本的协方差矩阵 C 的特征向量 V，即为 PCA 主成分分析**”。其计算过程如下：
  1. 将原始数据按行组成ｍ行ｎ列样本矩阵 X（每行一个样本，每列为一维特征）
  2. 求出样本 X 的协方差矩阵 C 和样本均值 m；（Matlab 可使用 cov () 函数求样本的协方差矩阵 C，均值用 mean 函数）
  3. 求出协方差矩阵的特征值 D 及对应的特征向量 V；（Matlab 可使用 eigs () 函数求矩阵的特征值 D 和特征向量 V）
  4. 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前 k 行组成矩阵 P；（eigs () 返回特征值构成的向量本身就是从大到小排序的）
  5. Y=(X-m)×P 即为降维到 k 维后的数据；**将主成分还原为原始自变量**：$Y×P的逆 +m = X_原$
* 由主成分分析法构造回归模型。即把各主成分作为新自变量代替原来自变量 x 做回归分析，**然后在把主成分还原为原来的自变量**。



4. 聚类分析——以FCM（模糊C均值聚类）为例
   * 模糊 C 均值（Fuzzy C-means）算法简称 FCM 算法，是一种基于目标函数的模糊聚类算法，主要用于数据的聚类分析。理论成熟，应用广泛，是一种优秀的聚类算法。见我的Google书签。
   * [~,label] = max(U); %找到所属的类，
   * 此label即为：样本点具体被分到哪一类。==**已有可运行的代码**==

5. 因子分析
   * 因子分析是一种数据简化技术，通过研究众多变量之间的**内部依赖关系**，探求**观测数据的基本结构**，并用少数几个**假想变量（因子）**来表示原始数据。
   * 因子的特点：
     * 因子个数远远少于原始变量个数
     * 因子之间没有线性关系
   * 步骤
     1. 选择分析变量
     2. 计算原始变量的相关系数矩阵
     3. 提取公因子
        * 取**方差（特征值）**大于0的因子
        * 因子的累计方差贡献率达到80%
     4. 因子旋转——因子的实际意义更容易解释
     5. 计算因子得分
   * 因子载荷，反映了第 i 个变量与第 j 个公共因子的相关系数，反映了第 i 个变量与第 j 个公共因子的相关重要性。绝对值越大，相关的密切程度越高。

